{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c89cadeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODOs - extract restaurant name, get rid of weird formatting (EX: <br&gt;<br&gt)\n",
    "### find way to get all reviews (not just first page)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = [15.0, 10.0]\n",
    "matplotlib.rcParams['font.size'] = 15\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9092101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename):\n",
    "    \"\"\"\n",
    "    Function to get the information from restaurant's Yelp page and put each review in a list\n",
    "    param filename: address of restaurant's Yelp site\n",
    "    return: list of basic restaurant info (name, street, category, price), list of separate reviews\n",
    "    \"\"\"\n",
    "    page = requests.get(filename)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    review_lines = soup.find_all('script', type = 'application/json')\n",
    "\n",
    "    #create a list to store basic restaurant info\n",
    "    restaurant_info = []\n",
    "    \n",
    "    #get restaurant name and street and add to info list\n",
    "    try:\n",
    "        info = soup.title.string.split('-')\n",
    "    except:\n",
    "        print('Could not get soup :/')\n",
    "        return [], []\n",
    "    restaurant = info[0]\n",
    "    restaurant_info.append(restaurant)\n",
    "    address = info[2][1:len(info[2])-17]\n",
    "    try:\n",
    "        street = address[address.index(' ')+1:]\n",
    "    except:\n",
    "        street = 'NA'\n",
    "    restaurant_info.append(street)\n",
    "    \n",
    "    string_review_line = str(review_lines[0])\n",
    "    #find food category, price and add to info list\n",
    "    info2= string_review_line[string_review_line.index('category_aliases'):string_review_line.index('review_count')].split(':')\n",
    "    category = info2[1][1:len(info2[1])-9]\n",
    "    restaurant_info.append(category)\n",
    "    price_tags = info2[6][1:len(info2[6])-9]\n",
    "    restaurant_info.append(price_tags)\n",
    "    \n",
    "    #find overall restaurant rating\n",
    "    string_rating_line = str(review_lines[1])\n",
    "    average_rating= string_rating_line[string_rating_line.index('stars from')-4:string_rating_line.index('stars from')]\n",
    "    restaurant_info.append(average_rating)\n",
    "    \n",
    "    #find reviews\n",
    "    split_start = string_review_line.split('comment')\n",
    "    try:\n",
    "        split_end = split_start[4].split('photos')\n",
    "    except:\n",
    "        print(\"could not read reviews :(\")\n",
    "        return restaurant_info, []\n",
    "    #create list of all the different reviews/ratings of customers\n",
    "    reviews = []\n",
    "    for i in range(len(split_start)):\n",
    "        reviews.append(split_start[i].split('photos')[0])\n",
    "    return restaurant_info, reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92836007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reviews(info, new_reviews, all_reviews):\n",
    "    \"\"\"\n",
    "    Function separate reviews into their features (restaurant name, street, category, price, review, date, rating)\n",
    "    param: separate reviews\n",
    "    return: cleaned list of reviews\n",
    "    \"\"\"\n",
    "    #clean up reviews to only have restaurant name, review, date, rating\n",
    "    for i in range(1, len(new_reviews)):\n",
    "        #DEBUGGING\n",
    "        #print(new_reviews[i])\n",
    "        #print()\n",
    "        if new_reviews[i].find(',\\\"language\\\"') == -1:\n",
    "            continue\n",
    "        else:\n",
    "            review_text = new_reviews[i][11:new_reviews[i].index(',\\\"language\\\"')-1:]\n",
    "        date = new_reviews[i][new_reviews[i].index('Date\\\":\\\"')+7:new_reviews[i].index('\\\",\\\"localized')]\n",
    "        rating = new_reviews[i][new_reviews[i].index('\\\"rating\\\":')+9: -2]\n",
    "        all_reviews.append([info[0],info[1],info[2],info[3],info[4],review_text,date,rating])\n",
    "    return all_reviews\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a8ed8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(clean_reviews):\n",
    "    \"\"\"\n",
    "    Function to create a data frame in pandas\n",
    "    param: list of all cleaned reviews\n",
    "    return: dataframe\n",
    "    \"\"\"\n",
    "    #create dataframe in pandas\n",
    "    df = pd.DataFrame(clean_reviews, columns=['Name', 'Street', 'Category', 'Price Tags','Average Rating','Review', 'Date', 'Rating'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4e480f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.yelp.com/biz/the-farmhouse-tap-and-grill-burlington\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load in the website data\n",
    "infile = open('ultimate_websites.txt', 'r')\n",
    "#file with all the restaurant's Yelp sites that we will be using - each line has a web address\n",
    "lines = infile.readlines()\n",
    "\n",
    "#initialize list to put all the cleaned reviews in\n",
    "all_reviews = []\n",
    "\n",
    "#loop through all restaurant Yelp websites in the file\n",
    "for website in lines:\n",
    "    print(website)\n",
    "    info, new_reviews = extract_data(website.strip())\n",
    "    \n",
    "    #if this doesn't work, go to the next website\n",
    "    if new_reviews == []:\n",
    "        continue\n",
    "    \n",
    "    #print(new_reviews)\n",
    "    all_reviews = clean_reviews(info, new_reviews, all_reviews)\n",
    "infile.close()\n",
    "\n",
    "#create a dataframe\n",
    "df = create_dataframe(all_reviews)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cab4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv('reviews_data_humongous.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01bf3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823200f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
